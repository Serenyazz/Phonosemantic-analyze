{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ruccent import Accent\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#Функции для обработки слова из \"слова\" --> ['с', 'л', 'О', 'в', 'а']\n",
    "def word_maker(word: str) -> list[str]:\n",
    "    \"\"\"Главная функция разделения слова и его подготовки\"\"\"\n",
    "    word = mark_softness(re.sub(r'[^а-яё]', '', word.lower()))\n",
    "    word = mark_stress(word)\n",
    "    return word\n",
    "\n",
    "def mark_stress(lst_word: list[str]) -> str:\n",
    "    \"\"\"Указывает ударение в русском слове.\"\"\"\n",
    "    accenter = Accent()\n",
    "    word = ''.join(lst_word).replace(\"'\", '')\n",
    "    index = accenter.predict(word)\n",
    "    lst_word[index] = chr(ord(lst_word[index])-32)\n",
    "    return lst_word\n",
    "\n",
    "def mark_softness(word: str) -> list[str]:\n",
    "    \"\"\"Указывает в слове мягкие согласные\"\"\"\n",
    "    letters = []\n",
    "\n",
    "    for i in range(1, len(word)):\n",
    "        if (word[i] in 'яёеюиь' and word[i-1] not in 'ьъщжшцеуэоаыяию') or word[i-1] in 'йчщ':\n",
    "            letters.append(word[i-1]+\"'\")\n",
    "        else:\n",
    "            letters.append(word[i-1])\n",
    "    if word[-1] in 'йчщ':\n",
    "        letters.append(word[-1] + \"'\")\n",
    "    else:\n",
    "        letters.append(word[-1])\n",
    "    return [i for i in letters if i not in 'ьъ']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#тест на каких-то рандомных словах\n",
    "lst = ['воробей', 'Котенок', 'розовый', 'Карандаш', 'девочка', 'Морда', 'Море', 'конфетка']\n",
    "for word in lst:\n",
    "    print(f'{word} - {word_maker(word)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Функции подготовки датасета, разбор слова, считывание excel, csv и запись#всех данных в одну csv таблицу.\n",
    "def examples(word):\n",
    "  \"\"\"Мы учитываем коэффициенты букв, их частоты, ударения и позицию, также мы смотрим на мягкость каждой буквы.\"\"\"\n",
    "\n",
    "  pd_values, pd_frequency = get_data()\n",
    "\n",
    "  word = word_maker(word)\n",
    "\n",
    "  k_total = 0   # (mx/freq) - ki\n",
    "  ki = 0\n",
    "  f_total = 0   # val - fi\n",
    "\n",
    "  max_frequency = max([pd_frequency['values'][let] for let in word])\n",
    "  for i in range(len(word)):\n",
    "      if not i:\n",
    "          ki = 4 * (max_frequency / pd_frequency['values'][word[i]])\n",
    "      elif word[i] in 'УЕЫАОЭЮИЯ':\n",
    "          ki = 2 * (max_frequency / pd_frequency['values'][word[i]])\n",
    "      else:\n",
    "          ki = (max_frequency / pd_frequency['values'][word[i]])\n",
    "      f_total += ki*pd_values['values'][word[i].lower()]\n",
    "      k_total += ki\n",
    "\n",
    "  return f_total, k_total\n",
    "\n",
    "def get_data():\n",
    "  '''Функция считывает данные для подготовки слова (частоту и значения)'''\n",
    "  pd_values = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/letters.csv', index_col='letters')\n",
    "  pd_frequency = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/frequency.csv', index_col='letters')\n",
    "  return pd_values, pd_frequency\n",
    "\n",
    "def get_excel():\n",
    "  '''Функция достаёт из excel таблицы нужные данные и возвращает словарь из них'''\n",
    "  dct = {}\n",
    "  book = openpyxl.open('words.xlsx', read_only=True)\n",
    "  sheet1 = book.active\n",
    "  for col in range(1, 89):\n",
    "      dct[sheet1[col][0].value] = float(sheet1[col][1].value)\n",
    "  return dct\n",
    "\n",
    "# Нежный-Грубый\n",
    "def create_dataset():\n",
    "  '''Функция создаёт нужный датасет с данными  - слово, y, 1ый параметр(f), 2ой параметр(k), и то, что мы могли бы посчитать сами(f/k)'''\n",
    "  f_lst = []\n",
    "  k_lst = []\n",
    "  fk_lst = []\n",
    "  df = pd.read_csv('DataSet0_1.csv', encoding='UTF-8')\n",
    "  rows = df.shape[0]\n",
    "\n",
    "  for i in range(0, rows):\n",
    "      f, k = examples(df['words'][i])\n",
    "      f_lst.append(f)\n",
    "      k_lst.append(k)\n",
    "      fk_lst.append(round(f/k, 3))\n",
    "\n",
    "  df['f'] = f_lst\n",
    "  df['k'] = k_lst\n",
    "  df['f/k'] = fk_lst\n",
    "\n",
    "  df.to_csv('NewDataSet0_1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text():\n",
    "  '''Достаёт нужные данные из заготовленной таблицы вида - слово, y'''\n",
    "  texts = []\n",
    "  book = openpyxl.open('Data.xlsx', read_only=True)\n",
    "  sheet = book.active\n",
    "\n",
    "  for row in range(1, sheet.max_row+1):\n",
    "      texts.append(sheet[row][0].value)\n",
    "  return texts\n",
    "\n",
    "def get_csv():\n",
    "  '''Делает из excel --> csv'''\n",
    "  excel = get_excel()\n",
    "  df = pd.DataFrame({\n",
    "      'words': excel.keys(),\n",
    "      'y': excel.values()})\n",
    "  df.to_csv('DataSet0_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/NewDataSet0_1.csv', index_col=0, encoding='UTF-8')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['f/k'], ec='black', color='#2196f3')\n",
    "plt.xlabel('ниже 2.5 нежный, выше 3.5 грубый')\n",
    "plt.ylabel('количество слов')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['k'], ec='black', color='#2196f3')\n",
    "plt.xlabel('Разбаловка k')\n",
    "plt.ylabel('количество слов')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['f'], ec='black', color='#2196f3')\n",
    "plt.xlabel('Разбаловка f')\n",
    "plt.ylabel('количество слов')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['f'])\n",
    "plt.title(f'F')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['k'])\n",
    "plt.title(f'K')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кореляция\n",
    "\n",
    "df['y'].corr(df['f/k'])\n",
    "df['y'].corr(df['f'])\n",
    "df['y'].corr(df['k'])\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df.corr(), annot=True, annot_kws={\"size\": 14})\n",
    "sns.set_style('white')\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['f'], df['k'])\n",
    "z = np.polyfit(df['f'], df['k'], 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(df['f'], p(df['f']))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Множественная Линейная Регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[['f', 'k']].values\n",
    "target = df[['y']].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=15)\n",
    "LinReg = LinearRegression()\n",
    "LinReg.fit(X_train, y_train)\n",
    "\n",
    "print('Training data score:', LinReg.score(X_train, y_train))\n",
    "print('Test data score:', LinReg.score(X_test, y_test))\n",
    "print('Intercept:', *LinReg.intercept_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data=LinReg.coef_, columns=['f', 'k'], index=['coef'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Трансформируем параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_log = np.log(df['k'])\n",
    "f_log = np.log(df['f'])\n",
    "\n",
    "sns.distplot(k_log)\n",
    "plt.title(f'Log f with skew {k_log.skew()}')\n",
    "plt.show()\n",
    "\n",
    "sns.distplot(f_log)\n",
    "plt.title(f'Log f with skew {f_log.skew()}')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель, которая использует логарифмы f и k, как основные параметры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['k_log'] = k_log\n",
    "df['f_log'] = f_log\n",
    "data = df[['k_log', 'f_log']]\n",
    "target = df[['y']].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=15)\n",
    "LinReg = LinearRegression()\n",
    "LinReg.fit(X_train, y_train)\n",
    "\n",
    "print('Training data score:', LinReg.score(X_train, y_train))\n",
    "print('Test data score:', LinReg.score(X_test, y_test))\n",
    "print('Intercept:', *LinReg.intercept_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data=LinReg.coef_, columns=['f', 'k'], index=['coef'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_check():\n",
    "    words = ['розовый', 'тюльпан', 'гвоздь', 'день', 'никита', 'юбка', 'бутылка', 'животное']\n",
    "    x_lst = []\n",
    "    y_lst = [1, 0, 1, 0, 0, 0, 1, 1]\n",
    "    for word in words:\n",
    "        x_lst.append(examples(word))\n",
    "    return words, x_lst, y_lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, X_predict, y_predict = predict_check()\n",
    "y_predicted = LinReg.predict(np.log(X_predict))\n",
    "for i in range(len(words)):\n",
    "  print(f\"Predict for '{words[i]}' - {1 if -3.5 > y_predicted[i] else 0}, should be - {y_predict[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['f_log'], df['k_log'])\n",
    "z = np.polyfit(df['f_log'], df['k_log'], 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(df['f_log'], p(df['f_log']))\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
